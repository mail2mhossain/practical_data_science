{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The current Numpy installation ('Z:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\py_caret\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py') fails to pass a sanity check due to a bug in the windows runtime. See this issue for more information: https://tinyurl.com/y3dm3h86",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-400ddc1e6fd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\ProgramData\\Anaconda3\\envs\\py_caret\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[0m_win_os_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0m_win_os_check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\ProgramData\\Anaconda3\\envs\\py_caret\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m_win_os_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m    300\u001b[0m                    \u001b[1;34m\"See this issue for more information: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                    \"https://tinyurl.com/y3dm3h86\")\n\u001b[1;32m--> 302\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The current Numpy installation ('Z:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\py_caret\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py') fails to pass a sanity check due to a bug in the windows runtime. See this issue for more information: https://tinyurl.com/y3dm3h86"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import shapiro, normaltest\n",
    "from tpot import TPOTClassifier\n",
    "from hpsklearn import HyperoptEstimator, pca, min_max_scaler, standard_scaler\n",
    "from hpsklearn import xgboost_classification, random_forest, ada_boost, gradient_boosting, extra_trees\n",
    "from hpsklearn import svc, svc_linear, svc_rbf, svc_poly, svc_sigmoid, liblinear_svc\n",
    "from hpsklearn import any_classifier\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe, hp\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt import BayesSearchCV\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, f1_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report,confusion_matrix,plot_confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, RFECV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d2bf997f7a25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/cancer_classification.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#df_train = pd.read_csv('Data/higgs_boson_training.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('Data/cancer_classification.csv')\n",
    "#df_train = pd.read_csv('Data/higgs_boson_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>benign_0__mal_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  benign_0__mal_1  \n",
       "0          0.4601                  0.11890                0  \n",
       "1          0.2750                  0.08902                0  \n",
       "2          0.3613                  0.08758                0  \n",
       "3          0.6638                  0.17300                0  \n",
       "4          0.2364                  0.07678                0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  benign_0__mal_1          569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# calculate duplicates\n",
    "dups = df_train.duplicated()\n",
    "#print(dups)\n",
    "# report if there are any duplicates\n",
    "print(dups.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: benign_0__mal_1, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"benign_0__mal_1\"].value_counts()\n",
    "#df_train[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malignant    357\n",
      "Benign       212\n",
      "Name: benign_0__mal_1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_names = {0:'Benign', 1:'Malignant'}\n",
    "print(df_train.benign_0__mal_1.value_counts().rename(index = class_names))()\n",
    "#df_train['Label'] = df_train['Label'].map({'b':0,'s':1})\n",
    "#df_train[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6839622641509433\n"
     ]
    }
   ],
   "source": [
    "Malignant = df_train[df_train['benign_0__mal_1']==1]\n",
    "Benign = df_train[df_train['benign_0__mal_1']==0]\n",
    "outlier_fraction = len(Malignant)/float(len(Benign))\n",
    "print (outlier_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['benign_0__mal_1'],axis=1)\n",
    "y = df_train['benign_0__mal_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Best Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Best Algorithm with Best Params Using HyperoptEstimator AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Started at: 2020-11-25 15:51:16.343676\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.14trial/s, best loss: 0.050000000000000044]\n",
      "100%|██████████| 2/2 [00:16<00:00,  8.23s/trial, best loss: 0.050000000000000044]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.85trial/s, best loss: 0.050000000000000044]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.25trial/s, best loss: 0.03749999999999998]\n",
      "100%|██████████| 5/5 [00:54<00:00, 10.86s/trial, best loss: 0.03749999999999998]\n",
      "100%|██████████| 6/6 [00:00<00:00,  6.55trial/s, best loss: 0.03749999999999998]\n",
      "100%|██████████| 7/7 [00:00<00:00,  9.97trial/s, best loss: 0.012499999999999956]\n",
      "100%|██████████| 8/8 [00:02<00:00,  3.40trial/s, best loss: 0.012499999999999956]\n",
      "100%|██████████| 9/9 [03:08<00:00, 20.96s/trial, best loss: 0.0] \n",
      "100%|██████████| 10/10 [00:04<00:00,  2.41trial/s, best loss: 0.0]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21.45trial/s, best loss: 0.0]\n",
      "100%|██████████| 12/12 [00:01<00:00, 11.56trial/s, best loss: 0.0]\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.50trial/s, best loss: 0.0]\n",
      "100%|██████████| 14/14 [00:01<00:00, 12.90trial/s, best loss: 0.0]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.09trial/s, best loss: 0.0]\n",
      "100%|██████████| 16/16 [00:00<00:00, 19.16trial/s, best loss: 0.0]\n",
      "100%|██████████| 17/17 [00:44<00:00,  2.63s/trial, best loss: 0.0]\n",
      "100%|██████████| 18/18 [00:10<00:00,  1.69trial/s, best loss: 0.0]\n",
      "100%|██████████| 19/19 [00:09<00:00,  1.99trial/s, best loss: 0.0]\n",
      "100%|██████████| 20/20 [00:00<00:00, 26.37trial/s, best loss: 0.0]\n",
      "100%|██████████| 21/21 [00:00<00:00, 22.98trial/s, best loss: 0.0]\n",
      "100%|██████████| 22/22 [00:30<00:00, 30.06s/trial, best loss: 0.0]"
     ]
    }
   ],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "accuracy = 0\n",
    "best_model = None\n",
    "#for i in range(100):\n",
    "    #print (i)\n",
    "model = HyperoptEstimator(  classifier= any_classifier('cla'), \n",
    "                                preprocessing= any_preprocessing('pre'), \n",
    "                                algo=tpe.suggest, \n",
    "                                max_evals=50, \n",
    "                                trial_timeout=5000)\n",
    "    # perform the search\n",
    "model.fit(X_train, y_train)\n",
    "acc = model.score(X_test, y_test)\n",
    "    #if acc > accuracy:\n",
    "        #accuracy = acc\n",
    "        #best_model = model\n",
    "        #print (accuracy)\n",
    "\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))\n",
    "print (f\"Job Ended at: {fin_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize the best model\n",
    "print(\"Accuracy: %.3f\" % acc)\n",
    "print(model.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "model = XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "              colsample_bylevel=0.50029110018247, colsample_bynode=1,\n",
    "              colsample_bytree=0.9371080486138555, gamma=0.00014999673883672553,\n",
    "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.15017743323882513, max_delta_step=0, max_depth=10,\n",
    "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
    "              n_estimators=1000, n_jobs=0, num_parallel_tree=1,\n",
    "              objective='multi:softprob', random_state=4,\n",
    "              reg_alpha=6.402887715271464e-05, reg_lambda=1.0516334360090362,\n",
    "              scale_pos_weight=1, seed=4, subsample=0.9995865341563067,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "model.fit(X_train, y_train,verbose=False,\n",
    "            early_stopping_rounds=10\n",
    "            #eval_set=[(X_valid,y_valid)]\n",
    "         )\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Best Algorithm with Best Params Using TPOT AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "\n",
    "# define model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search\n",
    "#model = TPOTClassifier(generations=5, population_size=50, cv=cv, scoring='accuracy', \n",
    "                       #verbosity=2, random_state=1, n_jobs=-1)\n",
    "tpot = TPOTClassifier(max_time_mins=120, cv=cv, scoring='accuracy', \n",
    "                       verbosity=2, random_state=1, n_jobs=-1)\n",
    "# perform the search\n",
    "tpot.fit(X_train_scaled, y_train)\n",
    "# export the best model\n",
    "tpot.export('tpot_Otto_best_model.py')\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))\n",
    "print (f\"Job Ended at: {fin_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Best Algorithm with Best Params Using PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import * \n",
    "from pycaret.datasets import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PyCaret Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "#fold_strategy = 'kfold' Default = 'stratifiedkfold'\n",
    "clf = setup(data = df_train, target = 'benign_0__mal_1', session_id=123,\n",
    "            data_split_stratify = True,\n",
    "            normalize = True, \n",
    "            normalize_method = 'minmax',\n",
    "            #transformation = True, \n",
    "            #transformation_method = 'quantile',\n",
    "            #pca = True,\n",
    "            #pca_method = 'incremental',\n",
    "            #feature_selection = True,\n",
    "            #feature_selection_threshold = 0.5,\n",
    "            #feature_selection_method = 'boruta',\n",
    "            #remove_outliers = True,\n",
    "            #outliers_threshold = 0.05,\n",
    "            fix_imbalance = True\n",
    "           )\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))\n",
    "print (f\"Job Ended at: {fin_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "#top3_models = compare_models(n_select = 3)\n",
    "best = compare_models()\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))\n",
    "print (f\"Job Ended at: {fin_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "best_model = finalize_model(best)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))\n",
    "print (f\"Job Ended at: {fin_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "#tuned_model = tune_model(best_model, optimize = 'AUC') # 'Recall'\n",
    "tuned_model = tune_model(best_model, optimize = 'F1')\n",
    "print(tuned_model)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))\n",
    "print (f\"Job Ended at: {fin_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_model(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Best Params of Gradient Boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### skopt Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_params[\"n_estimators\"]=(10, 100),\n",
    "#xgb_params['min_child_weight']=(1, 20),  \n",
    "#xgb_params['scale_pos_weight']= (1.0, 16.0),  For Imbalanced\n",
    "\n",
    "# define search space\n",
    "xgb_params = dict()\n",
    "#params['booster'] = ['gbtree', 'dart']\n",
    "#params[\"grow_policy\"]= [\"depthwise\", \"lossguide\"]\n",
    "xgb_params['learning_rate'] = (1e-7, 1.0, 'log-uniform')\n",
    "xgb_params['min_child_weight'] = (1e-16, 1e5, 'log-uniform')\n",
    "xgb_params['subsample'] = (0.5, 1.0)\n",
    "xgb_params['max_depth'] = (2, 20)\n",
    "xgb_params['colsample_bylevel'] = (0.5, 1.0)\n",
    "xgb_params['colsample_bytree'] = (0.5, 1.0)\n",
    "xgb_params['colsample_bynode'] = (0.5, 1.0)\n",
    "#xgb_params['max_delta_step'] = (0.1, 10)\n",
    "#xgb_params['bagging_temperature'] = (0.5, 1.0)\n",
    "#xgb_params['random_strength'] = (0.0, 100)\n",
    "xgb_params['reg_alpha'] = (0.0, 100)\n",
    "xgb_params['reg_lambda'] = (0.0, 100)\n",
    "#xgb_params['gamma'] = (0.0, 100)\n",
    "\n",
    "dart_param = dict()\n",
    "dart_param[\"sample_type\"]= [\"uniform\", \"weighted\"],\n",
    "dart_param[\"normalize_type\"]= [\"tree\", \"forest\"],\n",
    "dart_param[\"rate_drop\"]= (1e-8, 1.0),\n",
    "dart_param[\"skip_drop\"]= (1e-8, 1.0)\n",
    "           \n",
    "#if xgb_params[\"booster\"] == \"dart\":\n",
    "     #xgb_params.update(dart_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Multi-Classification - multi:softmax\n",
    "#For Binary Classificayion - binary:logistic\n",
    "xgb_model = XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        booster='dart'\n",
    "        n_estimators=10000, # use large n_estimators deliberately to make use of the early stopping\n",
    "        n_jobs=-1\n",
    "    )\n",
    "fit_params = {\n",
    "    'early_stopping_rounds':30,  \n",
    "    'eval_set':[(X_test, y_test)],\n",
    "    'verbose':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation\n",
    "#xgb_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=101)\n",
    "# define the search\n",
    "xgb_search = BayesSearchCV(estimator=xgb_model, search_spaces=xgb_params, fit_params=fit_params,\n",
    "                           cv=5, n_iter=50,\n",
    "                           verbose=0, n_jobs=-1,\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback handler\n",
    "def on_step(optim_result):\n",
    "    score = xgb_search.best_score_\n",
    "    print (f\"{datetime.now()}: Best Score- {score:.4f}\")\n",
    "    if score >= 0.98:\n",
    "        print('Interrupting!')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "# perform the search\n",
    "xgb_search.fit(X_train, y_train, callback=on_step)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pbounds = {\n",
    "    'learning_rate': (1e-7, 1.0),\n",
    "    'min_child_weight': (1e-16, 1e5),\n",
    "    'max_depth': (2,20),\n",
    "    'subsample': (0.3, 1.0),\n",
    "    'colsample_bylevel': (0.3, 1.0), \n",
    "    'colsample_bytree': (0.3, 1.0),\n",
    "    'colsample_bynode': (0.3, 1.0),\n",
    "    'reg_alpha': (0, 100),\n",
    "    'reg_lambda': (0, 100)\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_hyper_param(learning_rate,\n",
    "                        min_child_weight,\n",
    "                        max_depth,\n",
    "                        subsample,\n",
    "                        colsample_bylevel, \n",
    "                        colsample_bytree,\n",
    "                        colsample_bynode,\n",
    "                        reg_alpha,\n",
    "                        reg_lambda):\n",
    "\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    clf = XGBClassifier(\n",
    "        objective= \"multi:softmax\",\n",
    "        booster = \"dart\",\n",
    "        n_estimators = 10000,\n",
    "        learning_rate=learning_rate,\n",
    "        min_child_weight= min_child_weight,\n",
    "        max_depth=max_depth,\n",
    "        subsample= subsample,  \n",
    "        colsample_bylevel= colsample_bylevel, \n",
    "        colsample_bytree= colsample_bytree,\n",
    "        colsample_bynode= colsample_bynode,\n",
    "        reg_alpha= reg_alpha,\n",
    "        reg_lambda= reg_lambda\n",
    "        )\n",
    "    \n",
    "    fit_params = {\n",
    "        'early_stopping_rounds':30,\n",
    "        'eval_set':[(X_test, y_test)],\n",
    "        'verbose':0\n",
    "    }\n",
    "\n",
    "    #cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=101)\n",
    "    cv_result = np.mean(cross_val_score(estimator=clf, X=X_train, y=y_train, fit_params=fit_params, \n",
    "                                        cv=5, scoring='accuracy', verbose = 0))\n",
    "    return cv_result\n",
    "\n",
    "xgb_optimizer = BayesianOptimization(\n",
    "    f=xgboost_hyper_param,\n",
    "    pbounds=xgb_pbounds,\n",
    "    #verbose=2,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "init_points = 8 \n",
    "n_iter = 50 #The more steps the more likely to find a good maximum you are.\n",
    "xgb_optimizer.maximize(n_iter=n_iter, init_points=init_points)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCaret",
   "language": "python",
   "name": "py_caret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
