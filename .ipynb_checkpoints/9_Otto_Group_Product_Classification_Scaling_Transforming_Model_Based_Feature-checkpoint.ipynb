{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Z:\\ProgramData\\Anaconda3\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tpot import TPOTClassifier\n",
    "from hpsklearn import HyperoptEstimator, pca, min_max_scaler, standard_scaler\n",
    "from hpsklearn import xgboost_classification, random_forest, ada_boost, gradient_boosting, extra_trees\n",
    "from hpsklearn import svc, svc_linear, svc_rbf, svc_poly, svc_sigmoid, liblinear_svc\n",
    "from hpsklearn import any_classifier\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe, hp\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report,confusion_matrix,plot_confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, RFECV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Data/otto_group_Product_train.csv')\n",
    "#df_test = pd.read_csv('Data/otto_group_Product_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0  ...        1        0        0        0        0        0        0   \n",
       "1  ...        0        0        0        0        0        0        0   \n",
       "2  ...        0        0        0        0        0        0        0   \n",
       "3  ...        0        1        2        0        0        0        0   \n",
       "4  ...        1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61878, 95)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Class_1', 'Class_1', 'Class_1', ..., 'Class_9', 'Class_9',\n",
       "       'Class_9'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class_2    16122\n",
       "Class_6    14135\n",
       "Class_8     8464\n",
       "Class_3     8004\n",
       "Class_9     4955\n",
       "Class_7     2839\n",
       "Class_5     2739\n",
       "Class_4     2691\n",
       "Class_1     1929\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = df_train.drop(['id', 'target'],axis=1)\n",
    "y = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    # evaluate model  'accuracy'  'f1_micro'\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    #print('F-measure: %.3f' % score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "              colsample_bylevel=0.50029110018247, colsample_bynode=1,\n",
    "              colsample_bytree=0.9371080486138555, gamma=0.00014999673883672553,\n",
    "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.15017743323882513, max_delta_step=0, max_depth=10,\n",
    "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
    "              n_estimators=1000, n_jobs=0, num_parallel_tree=1,\n",
    "              objective='multi:softprob', random_state=4,\n",
    "              reg_alpha=6.402887715271464e-05, reg_lambda=1.0516334360090362,\n",
    "              scale_pos_weight=1, seed=4, subsample=0.9995865341563067,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test, max_features):\n",
    "    # configure to select a subset of features\n",
    "    # Based on RFE Value\n",
    "    fs = SelectFromModel(RandomForestClassifier(n_estimators=1000), max_features=max_features)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_features = [i+1 for i in range(X.shape[1])]\n",
    "max_features = [70, 80, 90, 93]\n",
    "print (max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in max_features:\n",
    "    # feature selection\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, k)\n",
    "    model.fit(X_train_fs, y_train)\n",
    "    # evaluate the model\n",
    "    yhat = model.predict(X_test_fs)\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, yhat)\n",
    "    print(f'K -> {k}: Accuracy {accuracy}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 30\n",
    "max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Select From Model Pipeline (Scaling + Transforming + SelectFromModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get modeling pipelines to evaluate\n",
    "def get_pipelines(model):\n",
    "    pipelines = list()\n",
    "    # SelectFromModel\n",
    "    p = Pipeline([('m', model)])\n",
    "    pipelines.append(('SelectFromModel', p))\n",
    "    # power and SelectFromModel\n",
    "    p = Pipeline([('p', PowerTransformer()), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('power_SelectFromModel', p))\n",
    "    # Quantile and SelectFromModel\n",
    "    p = Pipeline([('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('quantile_SelectFromModel', p))\n",
    "    # normalize and SelectFromModel\n",
    "    p = Pipeline([('n', MinMaxScaler()), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('norm_SelectFromModel', p))\n",
    "    # normalize and power and SelectFromModel\n",
    "    p = Pipeline([('n', MinMaxScaler()), ('p', PowerTransformer()), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('norm_power_SelectFromModel', p))\n",
    "    # normalize and Quantile and SelectFromModel\n",
    "    p = Pipeline([('n', MinMaxScaler()), \n",
    "                  ('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('norm_quantile_SelectFromModel', p))\n",
    "    # standardize and SelectFromModel\n",
    "    p = Pipeline([('s', StandardScaler()),  \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('std_SelectFromModel', p))\n",
    "    # standardize and power and SelectFromModel\n",
    "    p = Pipeline([('s', StandardScaler()), ('p', PowerTransformer()), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('std_power_SelectFromModel', p))\n",
    "    # standardize and Quantile and SelectFromModel\n",
    "    p = Pipeline([('s', StandardScaler()), \n",
    "                  ('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('std_quantile_SelectFromModel', p))\n",
    "    # Robust and SelectFromModel\n",
    "    p = Pipeline([('r', RobustScaler(with_centering=False, with_scaling=True)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('robust_SelectFromModel', p))\n",
    "    # Robust and power and SelectFromModel\n",
    "    p = Pipeline([('r', RobustScaler(with_centering=False, with_scaling=True)), ('p', PowerTransformer()), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('robust_power_SelectFromModel', p))\n",
    "    # Robust and Quantile and SelectFromModel\n",
    "    p = Pipeline([('r', RobustScaler(with_centering=False, with_scaling=True)), \n",
    "                  ('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('robust_quantile_SelectFromModel', p))\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Pipeline (Scaling + Transforming + SelectFromModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pipeline(name, pipeline, X_train, y_train, X_test, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    print('> %s: %.3f' % (name, accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "# get the modeling pipelines\n",
    "pipelines = get_pipelines(model)\n",
    "print (f\"Total Models: {len(pipelines)}\")\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test, max_features)\n",
    "# evaluate each pipeline\n",
    "for name, pipeline in pipelines:\n",
    "    fit_pipeline(name, pipeline, X_train_fs, y_train, X_test_fs, y_test)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Remove correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Identify Highly Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
      "feat_1   1.000000  0.031332  0.027807  0.027529  0.042973  0.043603  0.298952   \n",
      "feat_2   0.031332  1.000000  0.082573  0.134987  0.020926  0.041343  0.222386   \n",
      "feat_3   0.027807  0.082573  1.000000  0.583523  0.010880  0.004288  0.001294   \n",
      "feat_4   0.027529  0.134987  0.583523  1.000000  0.017290  0.014059  0.014490   \n",
      "feat_5   0.042973  0.020926  0.010880  0.017290  1.000000  0.145355  0.075047   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "feat_89  0.096851  0.105527  0.174781  0.183715  0.119951  0.035042  0.063511   \n",
      "feat_90  0.010310  0.515022  0.015068  0.009454  0.004842  0.054034  0.129578   \n",
      "feat_91  0.037264  0.026383  0.012417  0.010312  0.012012  0.012465  0.068506   \n",
      "feat_92  0.054777  0.008219  0.066921  0.087631  0.065331  0.015479  0.032261   \n",
      "feat_93  0.081783  0.054593  0.006814  0.015746  0.002038  0.008521  0.034912   \n",
      "\n",
      "           feat_8    feat_9   feat_10  ...   feat_84   feat_85   feat_86  \\\n",
      "feat_1   0.056321  0.032285  0.097776  ...  0.049634  0.008739  0.107947   \n",
      "feat_2   0.019815  0.025630  0.051925  ...  0.009845  0.006764  0.039090   \n",
      "feat_3   0.053462  0.063551  0.036944  ...  0.011159  0.048626  0.096093   \n",
      "feat_4   0.046184  0.046250  0.059514  ...  0.005684  0.033153  0.071029   \n",
      "feat_5   0.035861  0.024708  0.091324  ...  0.467329  0.034062  0.013879   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "feat_89  0.007974  0.019147  0.061498  ...  0.103643  0.053582  0.011822   \n",
      "feat_90  0.026807  0.020698  0.049908  ...  0.006013  0.003931  0.019803   \n",
      "feat_91  0.095990  0.014742  0.024025  ...  0.003444  0.023091  0.024005   \n",
      "feat_92  0.013608  0.069707  0.006869  ...  0.048431  0.043484  0.049393   \n",
      "feat_93  0.005131  0.006038  0.041316  ...  0.003723  0.023390  0.029035   \n",
      "\n",
      "          feat_87   feat_88   feat_89   feat_90   feat_91   feat_92   feat_93  \n",
      "feat_1   0.089374  0.020830  0.096851  0.010310  0.037264  0.054777  0.081783  \n",
      "feat_2   0.047451  0.047035  0.105527  0.515022  0.026383  0.008219  0.054593  \n",
      "feat_3   0.009838  0.082336  0.174781  0.015068  0.012417  0.066921  0.006814  \n",
      "feat_4   0.005055  0.067484  0.183715  0.009454  0.010312  0.087631  0.015746  \n",
      "feat_5   0.013999  0.019201  0.119951  0.004842  0.012012  0.065331  0.002038  \n",
      "...           ...       ...       ...       ...       ...       ...       ...  \n",
      "feat_89  0.066008  0.022552  1.000000  0.027764  0.015917  0.129622  0.030650  \n",
      "feat_90  0.014696  0.031679  0.027764  1.000000  0.014812  0.035311  0.039864  \n",
      "feat_91  0.028850  0.033653  0.015917  0.014812  1.000000  0.104226  0.000045  \n",
      "feat_92  0.001424  0.070120  0.129622  0.035311  0.104226  1.000000  0.003653  \n",
      "feat_93  0.499990  0.008631  0.030650  0.039864  0.000045  0.003653  1.000000  \n",
      "\n",
      "[93 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = X.corr().abs()\n",
    "print(); print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
      "feat_1      NaN  0.031332  0.027807  0.027529  0.042973  0.043603  0.298952   \n",
      "feat_2      NaN       NaN  0.082573  0.134987  0.020926  0.041343  0.222386   \n",
      "feat_3      NaN       NaN       NaN  0.583523  0.010880  0.004288  0.001294   \n",
      "feat_4      NaN       NaN       NaN       NaN  0.017290  0.014059  0.014490   \n",
      "feat_5      NaN       NaN       NaN       NaN       NaN  0.145355  0.075047   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "feat_89     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "feat_90     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "feat_91     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "feat_92     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "feat_93     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "           feat_8    feat_9   feat_10  ...   feat_84   feat_85   feat_86  \\\n",
      "feat_1   0.056321  0.032285  0.097776  ...  0.049634  0.008739  0.107947   \n",
      "feat_2   0.019815  0.025630  0.051925  ...  0.009845  0.006764  0.039090   \n",
      "feat_3   0.053462  0.063551  0.036944  ...  0.011159  0.048626  0.096093   \n",
      "feat_4   0.046184  0.046250  0.059514  ...  0.005684  0.033153  0.071029   \n",
      "feat_5   0.035861  0.024708  0.091324  ...  0.467329  0.034062  0.013879   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "feat_89       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "feat_90       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "feat_91       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "feat_92       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "feat_93       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "\n",
      "          feat_87   feat_88   feat_89   feat_90   feat_91   feat_92   feat_93  \n",
      "feat_1   0.089374  0.020830  0.096851  0.010310  0.037264  0.054777  0.081783  \n",
      "feat_2   0.047451  0.047035  0.105527  0.515022  0.026383  0.008219  0.054593  \n",
      "feat_3   0.009838  0.082336  0.174781  0.015068  0.012417  0.066921  0.006814  \n",
      "feat_4   0.005055  0.067484  0.183715  0.009454  0.010312  0.087631  0.015746  \n",
      "feat_5   0.013999  0.019201  0.119951  0.004842  0.012012  0.065331  0.002038  \n",
      "...           ...       ...       ...       ...       ...       ...       ...  \n",
      "feat_89       NaN       NaN       NaN  0.027764  0.015917  0.129622  0.030650  \n",
      "feat_90       NaN       NaN       NaN       NaN  0.014812  0.035311  0.039864  \n",
      "feat_91       NaN       NaN       NaN       NaN       NaN  0.104226  0.000045  \n",
      "feat_92       NaN       NaN       NaN       NaN       NaN       NaN  0.003653  \n",
      "feat_93       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
      "\n",
      "[93 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select upper triangle of correlation matrix\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "print(); print(upper_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feat_45']\n"
     ]
    }
   ],
   "source": [
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Drop Marked Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
      "0       1       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       1       0   \n",
      "2       0       0       0       0       0       0       0       1       0   \n",
      "3       1       0       0       1       6       1       5       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   feat_10  ...  feat_84  feat_85  feat_86  feat_87  feat_88  feat_89  \\\n",
      "0        0  ...        0        1        0        0        0        0   \n",
      "1        0  ...        0        0        0        0        0        0   \n",
      "2        0  ...        0        0        0        0        0        0   \n",
      "3        1  ...       22        0        1        2        0        0   \n",
      "4        0  ...        0        1        0        0        0        0   \n",
      "\n",
      "   feat_90  feat_91  feat_92  feat_93  \n",
      "0        0        0        0        0  \n",
      "1        0        0        0        0  \n",
      "2        0        0        0        0  \n",
      "3        0        0        0        0  \n",
      "4        1        0        0        0  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop features \n",
    "if len(to_drop) > 0:\n",
    "    X = X.drop(X[to_drop], axis=1)\n",
    "    print (X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Evaluate Pipeline (Scaling + Transforming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "# get the modeling pipelines\n",
    "pipelines = get_pipelines(model)\n",
    "print (len(pipelines))\n",
    "# evaluate each pipeline\n",
    "for name, pipeline in pipelines:\n",
    "    fit_pipeline(name, pipeline, X_train, y_train, X_test, y_test)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
