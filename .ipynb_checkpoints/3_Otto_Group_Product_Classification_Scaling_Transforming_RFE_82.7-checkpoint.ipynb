{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhossain/anaconda3/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tpot import TPOTClassifier\n",
    "from hpsklearn import HyperoptEstimator, pca, min_max_scaler, standard_scaler\n",
    "from hpsklearn import xgboost_classification, random_forest, ada_boost, gradient_boosting, extra_trees\n",
    "from hpsklearn import svc, svc_linear, svc_rbf, svc_poly, svc_sigmoid, liblinear_svc\n",
    "from hpsklearn import any_classifier\n",
    "from hpsklearn import any_preprocessing\n",
    "from hyperopt import tpe, hp\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report,confusion_matrix,plot_confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, RFECV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Data/otto_group_Product_train.csv')\n",
    "#df_test = pd.read_csv('Data/otto_group_Product_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0  ...        1        0        0        0        0        0        0   \n",
       "1  ...        0        0        0        0        0        0        0   \n",
       "2  ...        0        0        0        0        0        0        0   \n",
       "3  ...        0        1        2        0        0        0        0   \n",
       "4  ...        1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61878, 95)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Class_1', 'Class_1', 'Class_1', ..., 'Class_9', 'Class_9',\n",
       "       'Class_9'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class_2    16122\n",
       "Class_6    14135\n",
       "Class_8     8464\n",
       "Class_3     8004\n",
       "Class_9     4955\n",
       "Class_7     2839\n",
       "Class_5     2739\n",
       "Class_4     2691\n",
       "Class_1     1929\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = df_train.drop(['id', 'target'],axis=1)\n",
    "y = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43314, 93)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    # evaluate model  'accuracy'  'f1_micro'\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    #print('F-measure: %.3f' % score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "              colsample_bylevel=0.50029110018247, colsample_bynode=1,\n",
    "              colsample_bytree=0.9371080486138555, gamma=0.00014999673883672553,\n",
    "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.15017743323882513, max_delta_step=0, max_depth=10,\n",
    "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
    "              n_estimators=1000, n_jobs=0, num_parallel_tree=1,\n",
    "              objective='multi:softprob', random_state=4,\n",
    "              reg_alpha=6.402887715271464e-05, reg_lambda=1.0516334360090362,\n",
    "              scale_pos_weight=1, seed=4, subsample=0.9995865341563067,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Find Optimal number of features (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Started at: 2020-11-15 01:59:41.876361\n",
      "Execution time :  0:39:38.489188\n"
     ]
    }
   ],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "#rfc = RandomForestClassifier(random_state=101)\n",
    "#rfecv = RFECV(estimator=rfc, step=1, cv=RepeatedStratifiedKFold(10), scoring='accuracy')\n",
    "rfecv = RFECV(estimator=RandomForestClassifier(n_estimators=1000, random_state=101))\n",
    "rfecv.fit(X_train, y_train)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 87\n"
     ]
    }
   ],
   "source": [
    "n_features = rfecv.n_features_\n",
    "print(f'Optimal number of features: {n_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00731202, 0.0040518 , 0.01241899, 0.01116241, 0.00197651,\n",
       "       0.00330553, 0.01498064, 0.01337249, 0.00412989, 0.04171915,\n",
       "       0.00248947, 0.0059908 , 0.03253525, 0.02614734, 0.01194113,\n",
       "       0.00925984, 0.00594922, 0.00469889, 0.00772869, 0.00381849,\n",
       "       0.00629115, 0.00332659, 0.01883343, 0.02754061, 0.02580626,\n",
       "       0.01598969, 0.00385833, 0.00465135, 0.00967903, 0.01316532,\n",
       "       0.01175661, 0.04620874, 0.00775855, 0.01825531, 0.00611078,\n",
       "       0.00740583, 0.01170817, 0.02991659, 0.00719551, 0.02333728,\n",
       "       0.01314149, 0.00517112, 0.00404715, 0.00531686, 0.00815644,\n",
       "       0.01802885, 0.00361922, 0.00787561, 0.00279535, 0.00997745,\n",
       "       0.01146715, 0.00530752, 0.00665557, 0.01167063, 0.00703373,\n",
       "       0.00859509, 0.03971245, 0.00792015, 0.01938818, 0.00288398,\n",
       "       0.01474889, 0.00359994, 0.00708055, 0.02383189, 0.0126068 ,\n",
       "       0.01605346, 0.01037368, 0.00818162, 0.0142885 , 0.00509412,\n",
       "       0.00526011, 0.01662553, 0.01149159, 0.00294511, 0.00854162,\n",
       "       0.00581946, 0.00925066, 0.00750995, 0.0097973 , 0.02331884,\n",
       "       0.00597288, 0.01685233, 0.00491251, 0.01871407, 0.00521336,\n",
       "       0.00714941, 0.00221816])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 30 50 80 81 83]\n"
     ]
    }
   ],
   "source": [
    "print(np.where(rfecv.support_ == False)[0])\n",
    "X_train_best_features = X_train.drop(X_train.columns[np.where(rfecv.support_ == False)[0]], axis=1)\n",
    "X_test_best_features = X_test.drop(X_test.columns[np.where(rfecv.support_ == False)[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43314, 87)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_best_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18564, 87)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_best_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pipeline (Scaling + Transforming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get modeling pipelines to evaluate\n",
    "def get_pipelines(model):\n",
    "    pipelines = list()\n",
    "    # xgb\n",
    "    p = Pipeline([('m', model)])\n",
    "    pipelines.append(('xgb', p))\n",
    "    # power\n",
    "    p = Pipeline([('p', PowerTransformer()), ('m', model)])\n",
    "    pipelines.append(('power', p))\n",
    "    # Quantile\n",
    "    p = Pipeline([('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), ('m', model)])\n",
    "    pipelines.append(('quantile', p))\n",
    "    # normalize\n",
    "    p = Pipeline([('n', MinMaxScaler()), ('m', model)])\n",
    "    pipelines.append(('norm', p))\n",
    "    # normalize and power\n",
    "    p = Pipeline([('n', MinMaxScaler()), ('p', PowerTransformer()), ('m', model)])\n",
    "    pipelines.append(('norm_power', p))\n",
    "    # normalize and Quantile\n",
    "    p = Pipeline([('n', MinMaxScaler()), \n",
    "                  ('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), ('m', model)])\n",
    "    pipelines.append(('norm_quantile', p))\n",
    "    # standardize\n",
    "    p = Pipeline([('s', StandardScaler()), ('m', model)])\n",
    "    pipelines.append(('std', p))\n",
    "    # standardize and power\n",
    "    p = Pipeline([('s', StandardScaler()), ('p', PowerTransformer()), ('m', model)])\n",
    "    pipelines.append(('std_power', p))\n",
    "    # standardize and Quantile\n",
    "    p = Pipeline([('s', StandardScaler()), \n",
    "                  ('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), ('m', model)])\n",
    "    pipelines.append(('std_quantile', p))\n",
    "    # Robust\n",
    "    p = Pipeline([('r', RobustScaler(with_centering=False, with_scaling=True)), ('m',model)])\n",
    "    pipelines.append(('robust', p))\n",
    "    # Robust and power\n",
    "    p = Pipeline([('r', RobustScaler(with_centering=False, with_scaling=True)), ('p', PowerTransformer()), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('robust_power', p))\n",
    "    # Robust and Quantile\n",
    "    p = Pipeline([('r', RobustScaler(with_centering=False, with_scaling=True)), \n",
    "                  ('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), ('m', model)])\n",
    "    pipelines.append(('robust_quantile', p))\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### RFE Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get modeling pipelines to evaluate\n",
    "def get_ref_pipelines(model, n_features):\n",
    "    pipelines = list()\n",
    "    # RFE\n",
    "    p = Pipeline([('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('rfe', p))\n",
    "    # power and RFE\n",
    "    p = Pipeline([('p', PowerTransformer()), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)),\n",
    "                  ('m', model)])\n",
    "    pipelines.append(('power_rfe', p))\n",
    "    # Quantile and RFE\n",
    "    p = Pipeline([('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('quantile_rfe', p))\n",
    "    # normalize and RFE\n",
    "    p = Pipeline([('n', MinMaxScaler()), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('norm_rfe', p))\n",
    "    # normalize and power and RFE\n",
    "    p = Pipeline([('n', MinMaxScaler()), ('p', PowerTransformer()), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('norm_power_rfe', p))\n",
    "    # normalize and Quantile and RFE\n",
    "    p = Pipeline([('n', MinMaxScaler()), \n",
    "                  ('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('norm_quantile_rfe', p))\n",
    "    # standardize and RFE\n",
    "    p = Pipeline([('s', StandardScaler()), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('std_rfe', p))\n",
    "    # standardize and power and RFE\n",
    "    p = Pipeline([('s', StandardScaler()), ('p', PowerTransformer()), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('std_power_rfe', p))\n",
    "    # standardize and Quantile and RFE\n",
    "    p = Pipeline([('s', StandardScaler()), \n",
    "                  ('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('std_quantile_rfe', p))\n",
    "    # Robust and RFE\n",
    "    p = Pipeline([('r', RobustScaler(with_centering=False, with_scaling=True)), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('robust_rfe', p))\n",
    "    # Robust and power and RFE\n",
    "    p = Pipeline([('r', RobustScaler(with_centering=False, with_scaling=True)), ('p', PowerTransformer()), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('robust_power_rfe', p))\n",
    "    # Robust and Quantile and RFE\n",
    "    p = Pipeline([('r', RobustScaler(with_centering=False, with_scaling=True)), \n",
    "                  ('q', QuantileTransformer(n_quantiles=100, output_distribution='normal')), \n",
    "                  ('rfe', RFE(estimator=RandomForestClassifier(random_state=101),n_features_to_select=n_features)), \n",
    "                  ('m', model)])\n",
    "    pipelines.append(('robust_quantile_rfe', p))\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Pipeline (Scaling + Transforming + RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pipeline(name, pipeline, X_train, y_train, X_test, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    print('> %s: %.4f' % (name, accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Started at: 2020-11-14 23:01:59.601354\n",
      "Total Models: 12\n",
      "[23:03:12] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> rfe: 0.824\n",
      "[23:16:41] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> power_rfe: 0.827\n",
      "[23:27:36] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> quantile_rfe: 0.826\n",
      "[23:37:28] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> norm_rfe: 0.824\n",
      "[23:47:00] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> norm_power_rfe: 0.825\n",
      "[23:56:22] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> norm_quantile_rfe: 0.826\n",
      "[00:05:16] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> std_rfe: 0.824\n",
      "[00:14:10] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> std_power_rfe: 0.827\n",
      "[00:27:45] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> std_quantile_rfe: 0.826\n",
      "[00:36:38] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> robust_rfe: 0.824\n",
      "[00:45:55] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> robust_power_rfe: 0.827\n",
      "[00:55:05] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> robust_quantile_rfe: 0.826\n",
      "Execution time :  2:01:24.543377\n"
     ]
    }
   ],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "# get the modeling pipelines\n",
    "pipelines = get_ref_pipelines(model, n_features)\n",
    "print (f\"Total Models: {len(pipelines)}\")\n",
    "# evaluate each pipeline\n",
    "for name, pipeline in pipelines:\n",
    "    fit_pipeline(name, pipeline, X_train, y_train, X_test, y_test)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Started at: 2020-11-15 02:39:20.488495\n",
      "Total Models: 12\n",
      "[02:39:20] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> xgb: 0.824\n",
      "[02:47:03] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> power: 0.826\n",
      "[02:55:12] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> quantile: 0.826\n",
      "[03:03:36] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> norm: 0.824\n",
      "[03:11:24] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> norm_power: 0.825\n",
      "[03:20:21] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> norm_quantile: 0.826\n",
      "[03:29:40] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> std: 0.824\n",
      "[03:38:29] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> std_power: 0.827\n",
      "[03:46:12] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> std_quantile: 0.826\n",
      "[03:54:30] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> robust: 0.824\n",
      "[04:03:04] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> robust_power: 0.826\n",
      "[04:10:51] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "> robust_quantile: 0.826\n",
      "Execution time :  1:39:53.767685\n"
     ]
    }
   ],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "# get the modeling pipelines\n",
    "pipelines = get_pipelines(model)\n",
    "print (f\"Total Models: {len(pipelines)}\")\n",
    "# evaluate each pipeline\n",
    "for name, pipeline in pipelines:\n",
    "    fit_pipeline(name, pipeline, X_train_best_features, y_train, X_test_best_features, y_test)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Remove correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Identify Highly Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
      "feat_1   1.000000  0.031332  0.027807  0.027529  0.042973  0.043603  0.298952   \n",
      "feat_2   0.031332  1.000000  0.082573  0.134987  0.020926  0.041343  0.222386   \n",
      "feat_3   0.027807  0.082573  1.000000  0.583523  0.010880  0.004288  0.001294   \n",
      "feat_4   0.027529  0.134987  0.583523  1.000000  0.017290  0.014059  0.014490   \n",
      "feat_5   0.042973  0.020926  0.010880  0.017290  1.000000  0.145355  0.075047   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "feat_89  0.096851  0.105527  0.174781  0.183715  0.119951  0.035042  0.063511   \n",
      "feat_90  0.010310  0.515022  0.015068  0.009454  0.004842  0.054034  0.129578   \n",
      "feat_91  0.037264  0.026383  0.012417  0.010312  0.012012  0.012465  0.068506   \n",
      "feat_92  0.054777  0.008219  0.066921  0.087631  0.065331  0.015479  0.032261   \n",
      "feat_93  0.081783  0.054593  0.006814  0.015746  0.002038  0.008521  0.034912   \n",
      "\n",
      "           feat_8    feat_9   feat_10  ...   feat_84   feat_85   feat_86  \\\n",
      "feat_1   0.056321  0.032285  0.097776  ...  0.049634  0.008739  0.107947   \n",
      "feat_2   0.019815  0.025630  0.051925  ...  0.009845  0.006764  0.039090   \n",
      "feat_3   0.053462  0.063551  0.036944  ...  0.011159  0.048626  0.096093   \n",
      "feat_4   0.046184  0.046250  0.059514  ...  0.005684  0.033153  0.071029   \n",
      "feat_5   0.035861  0.024708  0.091324  ...  0.467329  0.034062  0.013879   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "feat_89  0.007974  0.019147  0.061498  ...  0.103643  0.053582  0.011822   \n",
      "feat_90  0.026807  0.020698  0.049908  ...  0.006013  0.003931  0.019803   \n",
      "feat_91  0.095990  0.014742  0.024025  ...  0.003444  0.023091  0.024005   \n",
      "feat_92  0.013608  0.069707  0.006869  ...  0.048431  0.043484  0.049393   \n",
      "feat_93  0.005131  0.006038  0.041316  ...  0.003723  0.023390  0.029035   \n",
      "\n",
      "          feat_87   feat_88   feat_89   feat_90   feat_91   feat_92   feat_93  \n",
      "feat_1   0.089374  0.020830  0.096851  0.010310  0.037264  0.054777  0.081783  \n",
      "feat_2   0.047451  0.047035  0.105527  0.515022  0.026383  0.008219  0.054593  \n",
      "feat_3   0.009838  0.082336  0.174781  0.015068  0.012417  0.066921  0.006814  \n",
      "feat_4   0.005055  0.067484  0.183715  0.009454  0.010312  0.087631  0.015746  \n",
      "feat_5   0.013999  0.019201  0.119951  0.004842  0.012012  0.065331  0.002038  \n",
      "...           ...       ...       ...       ...       ...       ...       ...  \n",
      "feat_89  0.066008  0.022552  1.000000  0.027764  0.015917  0.129622  0.030650  \n",
      "feat_90  0.014696  0.031679  0.027764  1.000000  0.014812  0.035311  0.039864  \n",
      "feat_91  0.028850  0.033653  0.015917  0.014812  1.000000  0.104226  0.000045  \n",
      "feat_92  0.001424  0.070120  0.129622  0.035311  0.104226  1.000000  0.003653  \n",
      "feat_93  0.499990  0.008631  0.030650  0.039864  0.000045  0.003653  1.000000  \n",
      "\n",
      "[93 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = X.corr().abs()\n",
    "print(); print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
      "feat_1      NaN  0.031332  0.027807  0.027529  0.042973  0.043603  0.298952   \n",
      "feat_2      NaN       NaN  0.082573  0.134987  0.020926  0.041343  0.222386   \n",
      "feat_3      NaN       NaN       NaN  0.583523  0.010880  0.004288  0.001294   \n",
      "feat_4      NaN       NaN       NaN       NaN  0.017290  0.014059  0.014490   \n",
      "feat_5      NaN       NaN       NaN       NaN       NaN  0.145355  0.075047   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "feat_89     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "feat_90     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "feat_91     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "feat_92     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "feat_93     NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "           feat_8    feat_9   feat_10  ...   feat_84   feat_85   feat_86  \\\n",
      "feat_1   0.056321  0.032285  0.097776  ...  0.049634  0.008739  0.107947   \n",
      "feat_2   0.019815  0.025630  0.051925  ...  0.009845  0.006764  0.039090   \n",
      "feat_3   0.053462  0.063551  0.036944  ...  0.011159  0.048626  0.096093   \n",
      "feat_4   0.046184  0.046250  0.059514  ...  0.005684  0.033153  0.071029   \n",
      "feat_5   0.035861  0.024708  0.091324  ...  0.467329  0.034062  0.013879   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "feat_89       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "feat_90       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "feat_91       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "feat_92       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "feat_93       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
      "\n",
      "          feat_87   feat_88   feat_89   feat_90   feat_91   feat_92   feat_93  \n",
      "feat_1   0.089374  0.020830  0.096851  0.010310  0.037264  0.054777  0.081783  \n",
      "feat_2   0.047451  0.047035  0.105527  0.515022  0.026383  0.008219  0.054593  \n",
      "feat_3   0.009838  0.082336  0.174781  0.015068  0.012417  0.066921  0.006814  \n",
      "feat_4   0.005055  0.067484  0.183715  0.009454  0.010312  0.087631  0.015746  \n",
      "feat_5   0.013999  0.019201  0.119951  0.004842  0.012012  0.065331  0.002038  \n",
      "...           ...       ...       ...       ...       ...       ...       ...  \n",
      "feat_89       NaN       NaN       NaN  0.027764  0.015917  0.129622  0.030650  \n",
      "feat_90       NaN       NaN       NaN       NaN  0.014812  0.035311  0.039864  \n",
      "feat_91       NaN       NaN       NaN       NaN       NaN  0.104226  0.000045  \n",
      "feat_92       NaN       NaN       NaN       NaN       NaN       NaN  0.003653  \n",
      "feat_93       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
      "\n",
      "[93 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select upper triangle of correlation matrix\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "print(); print(upper_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feat_45']\n"
     ]
    }
   ],
   "source": [
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Drop Marked Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
      "0       1       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       1       0   \n",
      "2       0       0       0       0       0       0       0       1       0   \n",
      "3       1       0       0       1       6       1       5       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   feat_10  ...  feat_84  feat_85  feat_86  feat_87  feat_88  feat_89  \\\n",
      "0        0  ...        0        1        0        0        0        0   \n",
      "1        0  ...        0        0        0        0        0        0   \n",
      "2        0  ...        0        0        0        0        0        0   \n",
      "3        1  ...       22        0        1        2        0        0   \n",
      "4        0  ...        0        1        0        0        0        0   \n",
      "\n",
      "   feat_90  feat_91  feat_92  feat_93  \n",
      "0        0        0        0        0  \n",
      "1        0        0        0        0  \n",
      "2        0        0        0        0  \n",
      "3        0        0        0        0  \n",
      "4        1        0        0        0  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop features \n",
    "if len(to_drop) > 0:\n",
    "    X = X.drop(X[to_drop], axis=1)\n",
    "    print (X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Evaluate Pipeline (Scaling + Transforming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "init_time = datetime.now()\n",
    "print (f\"Job Started at: {init_time}\")\n",
    "# get the modeling pipelines\n",
    "pipelines = get_pipelines(model)\n",
    "print (len(pipelines))\n",
    "# evaluate each pipeline\n",
    "for name, pipeline in pipelines:\n",
    "    fit_pipeline(name, pipeline, X_train, y_train, X_test, y_test)\n",
    "fin_time = datetime.now()\n",
    "print(\"Execution time : \", (fin_time-init_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
