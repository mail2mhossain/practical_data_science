{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting, Stacking, and Super Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/heart_disease_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>male</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>male</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>male</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>male</td>\n",
       "      <td>non-anginal pain</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>no</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>female</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>no</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     sex                cp  trestbps   chol    fbs  restecg  thalach exang  oldpeak        slope   ca  thal  num\n",
       "0  63.0    male    typical angina     145.0  233.0   True      2.0    150.0    no      2.3  downsloping  0.0   6.0    0\n",
       "1  67.0    male      asymptomatic     160.0  286.0  False      2.0    108.0   yes      1.5         flat  3.0   3.0    1\n",
       "2  67.0    male      asymptomatic     120.0  229.0  False      2.0    129.0   yes      2.6         flat  2.0   7.0    1\n",
       "3  37.0    male  non-anginal pain     130.0  250.0  False      0.0    187.0    no      3.5  downsloping  0.0   3.0    0\n",
       "4  41.0  female   atypical angina     130.0  204.0  False      2.0    172.0    no      1.4    upsloping  0.0   3.0    0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "nominal_features = ['sex', 'cp', 'exang', 'slope', 'thal', 'fbs', 'restecg', 'ca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df[nominal_features],drop_first=True)\n",
    "df = df.drop(nominal_features,axis=1)\n",
    "df = pd.concat([df,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"num\", axis=1)\n",
    "y = df[\"num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 16) (303,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 16) (212,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_voting_model():\n",
    "    # create the sub models\n",
    "    estimators = []\n",
    "    model1 = LogisticRegression(solver='liblinear')\n",
    "    estimators.append(('logistic', model1))\n",
    "    model2 = LinearDiscriminantAnalysis()\n",
    "    estimators.append(('lda', model2))\n",
    "    model3 = DecisionTreeClassifier()\n",
    "    estimators.append(('cart', model3))\n",
    "    model4 = SVC(gamma='auto')\n",
    "    estimators.append(('svm', model4))\n",
    "    # create the ensemble model\n",
    "    ensemble = VotingClassifier(estimators=estimators, voting='hard')\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = create_voting_model()\n",
    "results = cross_val_score(ensemble, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787741935483871\n"
     ]
    }
   ],
   "source": [
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    \n",
    "    level0.append(('lr', LogisticRegression(solver='liblinear')))\n",
    "    \n",
    "    level0.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    \n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    \n",
    "    level0.append(('cart', DecisionTreeClassifier()))\n",
    "   \n",
    "    level0.append(('svm', SVC()))\n",
    "    \n",
    "    level0.append(('bayes', GaussianNB()))\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression(solver='liblinear')\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = get_stacking()\n",
    "results = cross_val_score(ensemble, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8393548387096775\n"
     ]
    }
   ],
   "source": [
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlens.ensemble import SuperLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(KNeighborsClassifier(n_neighbors=15, weights='distance', p=1))\n",
    "models.append(GaussianNB())\n",
    "models.append(SVC(C=1000))\n",
    "models.append(DecisionTreeClassifier(criterion='entropy', min_samples_split=300, max_leaf_nodes=200))\n",
    "models.append(RandomForestClassifier(n_estimators=300, min_samples_split=400, n_jobs=100))\n",
    "models.append(AdaBoostClassifier(n_estimators=400))\n",
    "models.append(GradientBoostingClassifier(learning_rate=0.9, min_samples_split=400))\n",
    "models.append(LinearDiscriminantAnalysis())\n",
    "#models.append(MLPClassifier())\n",
    "models.append(LogisticRegression(solver='liblinear', penalty='l1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=10,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=0, shuffle=True,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=10, raise_on_excep...9771AF0>)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=0)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=0, sample_size=212,\n",
       "       scorer=<function accuracy_score at 0x0000027659771AF0>,\n",
       "       shuffle=True, verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = SuperLearner(scorer=accuracy_score, folds=10, shuffle=True, sample_size=len(X_train), random_state=0)\n",
    "ensemble.add(models)\n",
    "ensemble.add_meta(AdaBoostClassifier(n_estimators=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Ensemble Learning : 80.22 %\n"
     ]
    }
   ],
   "source": [
    "ensemble.fit(X_train, y_train)\n",
    "ensemble_Y_pred = ensemble.predict(X_test)\n",
    "\n",
    "print('Accuracy using Ensemble Learning : {:.2f}'.format(accuracy_score(y_test, ensemble_Y_pred) * 100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list()\n",
    "models.append(LogisticRegression(solver='liblinear'))\n",
    "models.append(DecisionTreeClassifier())\n",
    "models.append(SVC(gamma='scale', probability=True))\n",
    "models.append(GaussianNB())\n",
    "models.append(KNeighborsClassifier())\n",
    "models.append(BaggingClassifier(n_estimators=1000))\n",
    "models.append(RandomForestClassifier(n_estimators=1000))\n",
    "models.append(ExtraTreesClassifier(n_estimators=1000))\n",
    "models.append(AdaBoostClassifier(n_estimators=1000))\n",
    "models.append(GradientBoostingClassifier(n_estimators=1000))\n",
    "#models.append(XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=10,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=None, shuffle=True,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=10, raise_on_ex...9771AF0>)],\n",
       "   n_jobs=-1, name='group-7', raise_on_exception=True, transformers=[])],\n",
       "   verbose=0)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=None, sample_size=212,\n",
       "       scorer=<function accuracy_score at 0x0000027659771AF0>,\n",
       "       shuffle=True, verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = SuperLearner(scorer=accuracy_score, folds=10, shuffle=True, sample_size=len(X_train))\n",
    "ensemble.add(models)\n",
    "ensemble.add_meta(LogisticRegression(solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=10,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=None, shuffle=True,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=10, raise_on_ex...9771AF0>)],\n",
       "   n_jobs=-1, name='group-7', raise_on_exception=True, transformers=[])],\n",
       "   verbose=0)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=None, sample_size=212,\n",
       "       scorer=<function accuracy_score at 0x0000027659771AF0>,\n",
       "       shuffle=True, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Ensemble Learning : 84.62 %\n"
     ]
    }
   ],
   "source": [
    "ensemble_Y_pred = ensemble.predict(X_test)\n",
    "\n",
    "print('Accuracy using Ensemble Learning : {:.2f}'.format(accuracy_score(y_test, ensemble_Y_pred) * 100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbaseconda5399315a2a954424bee177201f1b943d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
